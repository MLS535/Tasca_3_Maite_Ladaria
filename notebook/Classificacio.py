import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_extraction import DictVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier

import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

# 1Ô∏è‚É£ Carregar dataset
df = pd.read_csv("../dataset/penguins_size.csv")

# 2Ô∏è‚É£ Eliminar files amb NA
df = df.dropna()

# 3Ô∏è‚É£ Variable objectiu (species) ‚Üí num√®rica
le = LabelEncoder()
y = le.fit_transform(df["species"])

# 4Ô∏è‚É£ Separar variables num√®riques i categ√≤riques
num_features = [
    "culmen_length_mm",
    "culmen_depth_mm",
    "flipper_length_mm",
    "body_mass_g"
]

cat_features = [
    "island",
    "sex"
]

X_num = df[num_features]
X_cat = df[cat_features]

# 5Ô∏è‚É£ One-hot encoding de les variables categ√≤riques amb DictVectorizer
dv = DictVectorizer(sparse=False)
X_cat_dict = X_cat.to_dict(orient="records")
X_cat_oh = dv.fit_transform(X_cat_dict)

# 6Ô∏è‚É£ Concatenar variables num√®riques + categ√≤riques
X = np.hstack((X_num.values, X_cat_oh))

# 7Ô∏è‚É£ Train / Test split (80 / 20)
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=1,
    stratify=y
)

# 8Ô∏è‚É£ Normalitzaci√≥ (nom√©s variables num√®riques)
scaler = StandardScaler()

X_train_num = X_train[:, :len(num_features)]
X_test_num = X_test[:, :len(num_features)]

scaler.fit(X_train_num)

X_train[:, :len(num_features)] = scaler.transform(X_train_num)
X_test[:, :len(num_features)] = scaler.transform(X_test_num)

# 9Ô∏è‚É£ Entrenament del model
lr = OneVsRestClassifier(
    LogisticRegression(
        C=100.0,
        random_state=1,
        solver="lbfgs",
        max_iter=200
    )
)

lr.fit(X_train, y_train)

# üîü Accuracy b√†sica
print("Accuracy train:", lr.score(X_train, y_train))
print("Accuracy test:", lr.score(X_test, y_test))
